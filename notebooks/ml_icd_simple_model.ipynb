{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_icd_simple_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qMF2QZq4-x9r",
        "mmEVBHnp-1MS",
        "sy6OcuP8zz7K",
        "hgwg-rVEPORv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmwCw6Mur1EV"
      },
      "source": [
        "# INTRO\n",
        "\n",
        "Imports and GDrive mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhEeW9dDrRYD"
      },
      "source": [
        "#@title IMPORTS !!!\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import keras\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3lsmXGieV3s",
        "cellView": "form",
        "outputId": "9ddb56e6-8e28-40d7-b09d-489136075e6b"
      },
      "source": [
        "#@title !!! Drive mounting\n",
        "folder_name = \"224x224_full_6cat_data\" #@param {type:\"string\"}\n",
        "drive.mount(\"/content/drive\")\n",
        "base_path = f'/content/drive/My Drive/Studia/ML/{folder_name}/'\n",
        "models_path = '/content/drive/My Drive/Studia/ML/models/'\n",
        "print(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzwQsrjFWteB",
        "cellView": "form"
      },
      "source": [
        "#@title !!! Dir content loading \n",
        "numpy_batches = os.listdir(base_path)\n",
        "class_file = [fl for fl in numpy_batches if \"classes\" in fl][0]\n",
        "numpy_batches.remove(class_file)\n",
        "with open(os.path.join(base_path, class_file)) as fjson:\n",
        "  classes = json.load(fjson)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzzgqRh5r7Jh"
      },
      "source": [
        "# MODEL CREATION\n",
        "\n",
        "Model building: layers, compilation and summary\n",
        "\n",
        "`[CHOOSE ONE]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMF2QZq4-x9r"
      },
      "source": [
        "## > Simple model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLKotEMUa3vA"
      },
      "source": [
        "First: Train Model\n",
        "\n",
        "```\n",
        "[Layers]\n",
        "1. Flatten\n",
        "2. FC-128\n",
        "3. FC-19\n",
        " \n",
        "Input: 28x28 JPEG\n",
        " \n",
        "In sum: 100 epochs per batch\n",
        "dataset division: 80% training, 20% testing\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgXT4Zu5tvGH",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "11a60f45-13f6-477f-ccdb-9fe1f143975d"
      },
      "source": [
        "#@title Create model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# 1st layer\n",
        "# flatten output data\n",
        "model.add(layers.Flatten(input_shape=(28, 28, 3)))\n",
        "\n",
        "# 2nd layer\n",
        "model.add(layers.Dense( 128, activation='relu'))\n",
        "# 3rd layer\n",
        "model.add(layers.Dense( len(classes.keys()) ))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy']\n",
        ")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmEVBHnp-1MS"
      },
      "source": [
        "##  > Convolutional model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L6Oz_-t-6hE"
      },
      "source": [
        "```\n",
        "[Layers]\n",
        "1. Conv2D_64\n",
        "2. Maxpool2D, stride 2\n",
        "3. Conv2D_128\n",
        "4. Maxpool2D, stride 2\n",
        "5. Flatten\n",
        "6. FC-128\n",
        "7. FC-X\n",
        "\n",
        "Input: 28x28 JPEG\n",
        " \n",
        "In sum: 100 epochs per batch\n",
        "dataset division: 80% training, 20% testing\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdmEjur9-6zW",
        "cellView": "form"
      },
      "source": [
        "#@title Create model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# 1st layer\n",
        "# Convolution2D output data \n",
        "\n",
        "model.add(layers.Convolution2D( 64,\n",
        "          kernel_size=(3, 3),\n",
        "          strides=(1, 1),\n",
        "          padding='valid',\n",
        "          input_shape=(28, 28, 3),\n",
        "          activation='relu'\n",
        "          \n",
        "))\n",
        "# 2nd layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# 3rd layer\n",
        "# Convolution2D output data \n",
        "model.add(layers.Convolution2D( 128,\n",
        "          kernel_size=(3, 3),\n",
        "          strides=(1, 1),\n",
        "          padding='valid',\n",
        "          activation='relu'\n",
        "))\n",
        "# 4th layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# 5th layer\n",
        "# flatten output data \n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# 6th layer\n",
        "model.add(layers.Dense( 128, activation='relu'))\n",
        "\n",
        "# 7th layer\n",
        "model.add(layers.Dense( len(classes.keys()) ))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy']\n",
        ")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kms5nasOQnQo"
      },
      "source": [
        "## > Convolutional Model ++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH7a2D1rRkjt"
      },
      "source": [
        "```\n",
        "[Layers]\n",
        "1. Conv2D_64\n",
        "2. Maxpool2D, stride 2\n",
        "3. Conv2D_128\n",
        "4. Maxpool2D, stride 2\n",
        "3. Conv2D_256\n",
        "4. Maxpool2D, stride 2\n",
        "3. Conv2D_512\n",
        "4. Maxpool2D, stride 2\n",
        "5. Flatten\n",
        "6. FC-4096\n",
        "6. FC-128\n",
        "7. FC-X\n",
        " \n",
        "Input: 224x224 RGB JPEG\n",
        " \n",
        "In sum: 100 epochs per batch\n",
        "dataset division: 80% training, 20% testing\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N19rpSi3RjbX",
        "outputId": "b840007d-3392-401d-c2d6-35c5909145f5"
      },
      "source": [
        "#@title Create model\n",
        "model = tf.keras.models.Sequential(name=\"MODEL_BIQA\")\n",
        "\n",
        "# 1st layer\n",
        "# Convolution2D output data \n",
        "\n",
        "model.add(layers.Convolution2D( 64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='valid',\n",
        "        activation='relu',\n",
        "        name=\"Conv2D_64\",\n",
        "        input_shape=(None, 224, 224, 3),\n",
        "))\n",
        "# 2nd layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), name=\"MaxPool2D\"))\n",
        "\n",
        "# 3rd layer\n",
        "# Convolution2D output data \n",
        "model.add(layers.Convolution2D( 128,\n",
        "          kernel_size=(3, 3),\n",
        "          strides=(1, 1),\n",
        "          padding='valid',\n",
        "          activation='relu',\n",
        "          name=\"Conv2D_128\"\n",
        "))\n",
        "# 4th layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), name=\"MaxPool2D\"))\n",
        "\n",
        "# 5th layer\n",
        "# Convolution2D output data \n",
        "model.add(layers.Convolution2D( 256,\n",
        "          kernel_size=(3, 3),\n",
        "          strides=(1, 1),\n",
        "          padding='valid',\n",
        "          activation='relu',\n",
        "          name=\"Conv2D_256\"\n",
        "))\n",
        "# 6th layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), name=\"MaxPool2D\"))\n",
        "\n",
        "# 7th layer\n",
        "# Convolution2D output data \n",
        "model.add(layers.Convolution2D( 512,\n",
        "          kernel_size=(3, 3),\n",
        "          strides=(1, 1),\n",
        "          padding='valid',\n",
        "          activation='relu',\n",
        "          name=\"Conv2D_512\"\n",
        "))\n",
        "# 8th layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), name=\"MaxPool2D\"))\n",
        "\n",
        "# 9th layer\n",
        "# Convolution2D output data \n",
        "model.add(layers.Convolution2D( 1024,\n",
        "          kernel_size=(3, 3),\n",
        "          strides=(1, 1),\n",
        "          padding='valid',\n",
        "          activation='relu',\n",
        "          name=\"Conv2D_1024\"\n",
        "))\n",
        "# 10th layer\n",
        "# MaxPooling2D output data \n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2),name=\"MaxPool2D\"))\n",
        "\n",
        "# 11th layer\n",
        "# flatten output data \n",
        "model.add(layers.Flatten(name=\"Flatten\"))\n",
        "\n",
        "# 12th layer\n",
        "model.add(layers.Dense( 4096, activation='relu', name=\"FC_4096\"))\n",
        "\n",
        "# 13th layer\n",
        "model.add(layers.Dense( 128, activation='relu', name=\"FC_128\"))\n",
        "\n",
        "# 14th layer\n",
        "model.add(layers.Dense( len(classes.keys()), name=f\"FC_{len(classes.keys())}\" ))\n",
        "\n",
        "# 15th layer\n",
        "model.add(layers.Softmax(name=\"Softmax\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy']\n",
        ")\n",
        "model.build(input_shape=(None, 224, 224, 3))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwYCb3h7sGFM"
      },
      "source": [
        "# MODEL TRAINING AND EVALUATION\n",
        "\n",
        "Loading data in batches and fitting and evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy6OcuP8zz7K"
      },
      "source": [
        "## GUIDED WALKTHROUGH\n",
        "\n",
        "=== BATCH LOOP (in iter form) ==="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGXeCAR0C0Gp",
        "cellView": "form"
      },
      "source": [
        "#@title Create batch-iterator\n",
        "itbatch = iter(numpy_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vS1ED4PCyDi",
        "cellView": "form"
      },
      "source": [
        "#@title Take next file\n",
        "batch = next(itbatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdEVmFi2iytE",
        "cellView": "form"
      },
      "source": [
        "#@title Load data to variables from file \n",
        "with np.load(os.path.join(base_path, batch)) as data_batch:\n",
        "    x = data_batch['dataset']\n",
        "    y = data_batch['labels']\n",
        "print(f\"FILE: {batch} => dataset: {x.shape}, labels: {y.shape}, classes: {classes}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiMhfLLY_4z-"
      },
      "source": [
        "Load batch into shuffler to distinguish training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfm93wyeGSIz",
        "cellView": "form"
      },
      "source": [
        "#@title Make StratifiedKFold data divider and create iterator for folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "skfiter = skf.split(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM3djUH8wEdB",
        "cellView": "form"
      },
      "source": [
        "#@title Take next fold and split data into particular sets [training, testing]\n",
        "train_indices, test_indices = next(skfiter)\n",
        "\n",
        "x_train, x_test = x[train_indices], x[test_indices]\n",
        "y_train, y_test = y[train_indices], y[test_indices]\n",
        "print(f\"TRAIN: {train_indices[:10]} & TEST: {test_indices[:10]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFD_nUzxIGXp",
        "cellView": "form"
      },
      "source": [
        "#@title Train model\n",
        "model.fit(x=x_train, y=y_train, epochs=20, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYcAhQmfIJir",
        "cellView": "form"
      },
      "source": [
        "#@title Evaluate model after training cycle\n",
        "score = model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jauoudDtv2Oo"
      },
      "source": [
        "## ONE BLOCK TRAINING/VALIDATING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh9ELHXwv6jO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "afd07fcb-00e9-48db-d60b-d1d6a4161330"
      },
      "source": [
        "#@title Start training\n",
        "# === BATCH LOOP === #\n",
        "print(f\"Classes: {classes}\")\n",
        "start = time.time()\n",
        "for batch in numpy_batches[:3]:\n",
        "    batch_time = time.time()\n",
        "    with np.load(os.path.join(base_path, batch)) as data_batch:\n",
        "# Loading from *.npz\n",
        "        x = data_batch['dataset']\n",
        "        y = data_batch['labels']\n",
        "    print(f\"FILE: {batch} => dataset: {x.shape}, labels: {y.shape}\")\n",
        "\n",
        "# Splitting for training and evaluation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "    n = 0\n",
        "    for train_indices, test_indices in skf.split(x, y):    \n",
        "        x_train, x_test = x[train_indices], x[test_indices]\n",
        "        y_train, y_test = y[train_indices], y[test_indices]\n",
        "        n += 1\n",
        "# Training..\n",
        "        training = time.time()\n",
        "        model.fit(x=x_train, y=y_train, epochs=20, verbose=0)\n",
        "        print(f\" ->Fold_{n} training: {round(time.time() - training)}s..\")\n",
        "# Evaluating..\n",
        "        score = model.evaluate(x_test, y_test, verbose=1)\n",
        "    print(f\"--FILE: {batch} time: {round(time.time() - batch_time)}s.\")\n",
        "print(f\"Full training: {round(time.time() - start)}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgwg-rVEPORv"
      },
      "source": [
        "# SAVE / LOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19gRszayO48n",
        "cellView": "form",
        "outputId": "1319ab45-5cc1-44ce-b7dc-c7297f071eb0"
      },
      "source": [
        "#@title SAVE MODEL\n",
        "model_name = \"simple_fc_model\" #@param {type:\"string\"}\n",
        "model.save(os.path.join(models_path, model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Y81s5ZNOPTbH"
      },
      "source": [
        "#@title LOAD MODEL\n",
        "model_name = \"simple_fc_model\" #@param {type:\"string\"}\n",
        "model = keras.models.load_model(os.path.join(models_path, model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHb0w92SseP2"
      },
      "source": [
        "# MODEL TESTING\n",
        "\n",
        "We have now a model! Lets test its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6SV_JiSz5c7",
        "cellView": "form"
      },
      "source": [
        "#@title Load necessary functions to test model\n",
        "### Matplotlib functions to plot image\n",
        "import matplotlib.pyplot as plt\n",
        "classes_reversed = list(classes.keys())\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    true_label, img = true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(classes_reversed[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                classes_reversed[true_label]),\n",
        "                                color=color)\n",
        "  \n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    true_label = true_label[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks(range(6))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVgVuWVvxbof"
      },
      "source": [
        "# with np.load(os.path.join(base_path, numpy_batches[0])) as data:\n",
        "#     x = data['dataset']\n",
        "#     y = data['labels']\n",
        "\n",
        "# prob_model = tf.keras.Sequential([model, layers.Softmax()])\n",
        "\n",
        "predictions = prob_model.predict(x)\n",
        "\n",
        "### see results\n",
        "i = random.randint(0, len(x)-1)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], y, x)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  y)\n",
        "_ = plt.xticks(range(len(classes)), classes_reversed, rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}